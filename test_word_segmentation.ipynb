{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Khmer Word Segmentation\n",
    "Testing khmercut library for Khmer word segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting khmercut\n",
      "  Downloading khmercut-0.1.0.tar.gz (5.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m364.5 kB/s\u001b[0m  \u001b[33m0:00:16\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting python-crfsuite (from khmercut)\n",
      "  Downloading python_crfsuite-0.9.12-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.3 kB)\n",
      "Downloading python_crfsuite-0.9.12-cp311-cp311-macosx_11_0_arm64.whl (319 kB)\n",
      "Building wheels for collected packages: khmercut\n",
      "  Building wheel for khmercut (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for khmercut: filename=khmercut-0.1.0-py3-none-any.whl size=5872139 sha256=28db1b585d5e8a43177b34a8f03055d91592ac27945f28f2e24384aa2e596f7d\n",
      "  Stored in directory: /Users/macbookair/Library/Caches/pip/wheels/98/e8/2c/bf29d047ec29f274a676e0c0448bad56492c0de5c3ee21623c\n",
      "Successfully built khmercut\n",
      "Installing collected packages: python-crfsuite, khmercut\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [khmercut]\n",
      "\u001b[1A\u001b[2KSuccessfully installed khmercut-0.1.0 python-crfsuite-0.9.12\n"
     ]
    }
   ],
   "source": [
    "# Install khmercut\n",
    "!pip install khmercut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "លោកជំទាវបណ្ឌិតពេជចន្ទមុន្នីហ៊ុនម៉ាណែតបន្តប្រគេនភេសជ្ជៈ\n",
      "\n",
      "Tokenized:\n",
      "['លោកជំទាវ', 'បណ្ឌិត', 'ពេជចន្ទ', 'មុន្នី', 'ហ៊ុន', 'ម៉ាណែត', 'បន្ត', 'ប្រគេន', 'ភេសជ្ជៈ']\n",
      "\n",
      "Joined with spaces:\n",
      "លោកជំទាវ បណ្ឌិត ពេជចន្ទ មុន្នី ហ៊ុន ម៉ាណែត បន្ត ប្រគេន ភេសជ្ជៈ\n"
     ]
    }
   ],
   "source": [
    "# Test khmercut\n",
    "from khmercut import tokenize\n",
    "\n",
    "# Test text without spaces\n",
    "text_no_spaces = \"លោកជំទាវបណ្ឌិតពេជចន្ទមុន្នីហ៊ុនម៉ាណែតបន្តប្រគេនភេសជ្ជៈ\"\n",
    "\n",
    "# Tokenize\n",
    "tokens = tokenize(text_no_spaces)\n",
    "print(\"Original text:\")\n",
    "print(text_no_spaces)\n",
    "print(\"\\nTokenized:\")\n",
    "print(tokens)\n",
    "print(\"\\nJoined with spaces:\")\n",
    "print(' '.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  លោកអឿនប៉ាវទៅលេងខេត្តកំពត\n",
      "Output: លោក អឿន ប៉ាវ ទៅ លេង ខេត្ត កំពត\n",
      "--------------------------------------------------------------------------------\n",
      "Input:  ព្រះរាជាណាចក្រកម្ពុជា\n",
      "Output: ព្រះរាជាណាចក្រ កម្ពុជា\n",
      "--------------------------------------------------------------------------------\n",
      "Input:  សម្តេចបវរធិបតីហ៊ុនម៉ាណែត\n",
      "Output: សម្តេច បវរធិបតី ហ៊ុន ម៉ាណែត\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test with more examples\n",
    "from khmercut import tokenize\n",
    "\n",
    "test_sentences = [\n",
    "    \"លោកអឿនប៉ាវទៅលេងខេត្តកំពត\",\n",
    "    \"ព្រះរាជាណាចក្រកម្ពុជា\",\n",
    "    \"សម្តេចបវរធិបតីហ៊ុនម៉ាណែត\",\n",
    "]\n",
    "\n",
    "for text in test_sentences:\n",
    "    tokens = tokenize(text)\n",
    "    print(f\"Input:  {text}\")\n",
    "    print(f\"Output: {' '.join(tokens)}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text with spaces:\n",
      "ហ៊ុន ម៉ាណែត ទៅ ភ្នំពេញ\n",
      "\n",
      "Tokenized:\n",
      "ហ៊ុន   ម៉ាណែត   ទៅ   ភ្នំពេញ\n"
     ]
    }
   ],
   "source": [
    "# Test handling text that already has spaces\n",
    "from khmercut import tokenize\n",
    "\n",
    "text_with_spaces = \"ហ៊ុន ម៉ាណែត ទៅ ភ្នំពេញ\"\n",
    "\n",
    "tokens = tokenize(text_with_spaces)\n",
    "print(\"Text with spaces:\")\n",
    "print(text_with_spaces)\n",
    "print(\"\\nTokenized:\")\n",
    "print(' '.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: No spaces\n",
      "លោក អឿន ប៉ាវ ទៅ លេង ខេត្ត កំពត\n",
      "\n",
      "Test 2: With spaces\n",
      "ហ៊ុន ម៉ាណែត ទៅ ភ្នំពេញ\n"
     ]
    }
   ],
   "source": [
    "# Create a function that handles both cases\n",
    "from khmercut import tokenize\n",
    "\n",
    "def smart_tokenize(text):\n",
    "    \"\"\"\n",
    "    Smart tokenization that handles:\n",
    "    - Text without spaces (applies word segmentation)\n",
    "    - Text with spaces (uses existing tokenization)\n",
    "    \"\"\"\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Check if text already has spaces\n",
    "    if ' ' in text:\n",
    "        # Already tokenized, just split\n",
    "        return text.split()\n",
    "    else:\n",
    "        # No spaces, apply word segmentation\n",
    "        return tokenize(text)\n",
    "\n",
    "# Test both cases\n",
    "print(\"Test 1: No spaces\")\n",
    "result1 = smart_tokenize(\"លោកអឿនប៉ាវទៅលេងខេត្តកំពត\")\n",
    "print(' '.join(result1))\n",
    "\n",
    "print(\"\\nTest 2: With spaces\")\n",
    "result2 = smart_tokenize(\"ហ៊ុន ម៉ាណែត ទៅ ភ្នំពេញ\")\n",
    "print(' '.join(result2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
